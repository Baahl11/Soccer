"""
Advanced corner prediction model based on voting ensemble combining Random Forest and XGBoost.

This module implements a voting ensemble model for corner predictions based on academic research
showing that the integration of Random Forest and XGBoost in a voting model consistently 
achieves the highest accuracy for soccer predictions.

References:
- "Data-driven prediction of soccer outcomes using enhanced machine and deep learning techniques"
  Journal of Big Data, 2024
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, Any, List, Optional, Tuple, Union
from scipy.stats import nbinom, norm
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor
import pickle
import os
import joblib

class ModelError(Exception):
    """Custom exception for model-related errors"""
    pass

def setup_logging(log_file: str = 'corners_model.log'):
    """Configure logging with proper formatting and handlers"""
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # File handler
    if not os.path.exists('logs'):
        os.makedirs('logs')
    fh = logging.FileHandler(f'logs/{log_file}')
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(formatter)
    
    # Console handler
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(formatter)
    
    # Configure root logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    root_logger.addHandler(fh)
    root_logger.addHandler(ch)
    
    return root_logger

# Configurar logging al importar el mÃ³dulo
logger = setup_logging()

class VotingEnsembleCornersModel:
    """
    Voting ensemble model for predicting corner kicks in soccer matches based on
    academic research showing superior performance of combining Random Forest and XGBoost.
    """
    
    def __init__(self):
        """Initialize the voting ensemble model for corner predictions"""
        # Parameters based on academic research
        self.possession_impact = 0.48
        self.attacking_style_impact = 0.38
        self.defensive_deep_block_impact = 0.28
        self.bootstrap_ratio = 0.6  # For creating bootstrap samples
        
        # League-specific adjustment factors
        self.league_factors = {
            39: 1.05,  # Premier League - slightly more corners
            140: 0.95,  # La Liga - slightly fewer corners
            61: 1.10,  # Ligue 1 - more corners
            78: 0.90,  # Bundesliga - fewer corners
            135: 1.00,  # Serie A - average corners
        }
        
        # Base expectation (average corners per match)
        self.base_corners = 10.2
        
        # Initialize model state attributes
        self.is_fitted = False
        self.feature_names = [
            'home_avg_corners_for', 'home_avg_corners_against',
            'away_avg_corners_for', 'away_avg_corners_against',
            'home_form_score', 'away_form_score',
            'home_total_shots', 'away_total_shots', 'league_id',
            'home_elo', 'away_elo', 'elo_diff', 'elo_win_probability'
        ]
          # Try to load pre-trained models, or create new ones
        try:
            self.rf_model = self._load_model('random_forest_corners')
            self.xgb_model = self._load_model('xgboost_corners')
            if self.rf_model is None or self.xgb_model is None:
                logger.warning("One or more models could not be loaded. Using default prediction method.")
            else:
                # If models are loaded successfully, mark as fitted
                self.is_fitted = True
        except Exception as e:
            logger.error(f"Error loading ensemble models: {e}")
            self.rf_model = None
            self.xgb_model = None
    
    def _load_model(self, model_name: str) -> Optional[Any]:
        """Load a pre-trained model from file with improved version compatibility"""
        try:
            if 'xgboost' in model_name.lower():
                # Try multiple file extensions for XGBoost models
                possible_paths = [
                    f'models/{model_name}.json',
                    f'models/{model_name}.pkl',
                    f'models/{model_name}.joblib'
                ]
                
                for model_path in possible_paths:
                    if os.path.exists(model_path):
                        if model_path.endswith('.json'):
                            model = xgb.XGBRegressor()
                            model.load_model(model_path)
                            return model
                        elif model_path.endswith(('.pkl', '.joblib')):
                            return joblib.load(model_path)
            else:
                # Try multiple file extensions for Random Forest models
                possible_paths = [
                    f'models/{model_name}.joblib',
                    f'models/{model_name}.pkl'
                ]
                
                for model_path in possible_paths:
                    if os.path.exists(model_path):
                        return joblib.load(model_path)
                        
            logger.warning(f"Model file not found for {model_name}. Tried: {possible_paths}")
            return None
        except Exception as e:
            logger.error(f"Error loading model {model_name}: {e}")
            return None
    
    def predict_corners(
        self, 
        home_team_id: int, 
        away_team_id: int,
        home_stats: Dict[str, Any],
        away_stats: Dict[str, Any],
        league_id: int,
        context_factors: Optional[Dict[str, Any]] = None,
        referee_id: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Predict corner kicks using voting ensemble (RF + XGBoost) based on academic research.
        
        Args:
            home_team_id: ID of home team
            away_team_id: ID of away team
            home_stats: Stats for home team
            away_stats: Stats for away team
            league_id: League ID
            context_factors: Additional match context like weather, importance, etc.
            referee_id: Optional referee ID
                
        Returns:
            Dictionary with corner predictions
        """
        try:
            # Process features for model inputs
            features = self._extract_features(
                home_team_id, away_team_id, home_stats, away_stats, league_id, context_factors
            )
            
            # If we have both trained models, use the voting ensemble approach
            if self.rf_model is not None and self.xgb_model is not None:
                # Get predictions from both models
                rf_total, rf_home, rf_away = self._predict_with_rf(features)
                xgb_total, xgb_home, xgb_away = self._predict_with_xgb(features)
                
                # Weighted average (from paper, RF gets slightly higher weight)
                total_corners = (rf_total * 0.55) + (xgb_total * 0.45)
                home_corners = (rf_home * 0.55) + (xgb_home * 0.45)
                away_corners = (rf_away * 0.55) + (xgb_away * 0.45)
            else:
                # Fallback to statistical approach
                total_corners, home_corners, away_corners = self._statistical_corners_estimate(
                    home_team_id, away_team_id, home_stats, away_stats, league_id, context_factors
                )
            
            # Apply referee effect if available
            if referee_id:
                referee_factor = self._get_referee_factor(referee_id)
                total_corners *= referee_factor
                home_corners *= referee_factor
                away_corners *= referee_factor
            
            # Calculate over probabilities using negative binomial distribution
            # (research shows this is better than Poisson for corners)
            over_probs = self._calculate_over_probabilities(
                total_corners, home_corners, away_corners
            )
            
            # Calculate corner brackets for betting markets
            corner_brackets = self._calculate_corner_brackets(total_corners)
            
            # Return predictions with comprehensive information
            result = {
                'total': round(total_corners, 1),
                'home': round(home_corners, 1),
                'away': round(away_corners, 1),
                'over_8.5': round(over_probs.get('over_8.5', 0.65), 3),
                'over_9.5': round(over_probs.get('over_9.5', 0.52), 3),
                'over_10.5': round(over_probs.get('over_10.5', 0.38), 3),
                'corner_brackets': corner_brackets,
                'is_fallback': False,
                'model': 'voting_ensemble_rf_xgb',
                'confidence': self._calculate_prediction_confidence(
                    total_corners, home_corners, away_corners,
                    home_stats, away_stats, league_id
                )
            }
            
            # Add additional corner lines
            custom_lines = [7.5, 11.5, 12.5]
            for line in custom_lines:
                key = f"over_{line}"
                if key in over_probs:
                    result[key] = round(over_probs[key], 3)
            
            return result
            
        except Exception as e:
            logger.error(f"Error in voting ensemble corners prediction: {e}")
            return self._get_fallback_prediction()
    
    def _extract_features(
        self,
        home_team_id: int,
        away_team_id: int,
        home_stats: Dict[str, Any],
        away_stats: Dict[str, Any],
        league_id: int,
        context_factors: Optional[Dict[str, Any]]
    ) -> Dict[str, float]:
        """Extract features for model input"""
        try:
            # Import the Elo rating system here to avoid circular imports
            from team_elo_rating import get_elo_ratings_for_match
            
            # Examine the model to get feature names in the correct order
            feature_names = None
            if self.rf_model is not None:
                if hasattr(self.rf_model, 'feature_names_in_'):
                    feature_names = self.rf_model.feature_names_in_
                    logger.info(f"Using feature names from model: {feature_names}")
            
            # If we couldn't get feature names from the model, use our default list
            if feature_names is None:
                # These are the core features used during model training according to train_corner_models.py
                feature_names = [
                    'home_avg_corners_for', 'home_avg_corners_against',
                    'away_avg_corners_for', 'away_avg_corners_against',
                    'home_form_score', 'away_form_score',
                    'home_total_shots', 'away_total_shots', 'league_id',
                    'home_elo', 'away_elo', 'elo_diff', 'elo_win_probability'
                ]
                logger.info(f"Using default feature names: {feature_names}")
            
            # Create the features dictionary with the right values
            features = {}
            
            # Team stats
            features['home_avg_corners_for'] = float(home_stats.get('avg_corners_for', 5.0))
            features['home_avg_corners_against'] = float(home_stats.get('avg_corners_against', 5.0))
            features['away_avg_corners_for'] = float(away_stats.get('avg_corners_for', 4.5))
            features['away_avg_corners_against'] = float(away_stats.get('avg_corners_against', 5.5))
            
            # Team form - use names consistent with training features
            features['home_form_score'] = float(home_stats.get('form_score', 50))
            features['away_form_score'] = float(away_stats.get('form_score', 50))
            
            # Shot statistics if available
            features['home_total_shots'] = float(home_stats.get('total_shots', home_stats.get('avg_shots', 12.0)))
            features['away_total_shots'] = float(away_stats.get('total_shots', away_stats.get('avg_shots', 10.0)))
            
            # League ID
            features['league_id'] = float(league_id)
              # Add Elo rating features only if they are expected by the model
            try:
                # Get Elo ratings and probabilities
                elo_features = get_elo_ratings_for_match(home_team_id, away_team_id, league_id)
                
                # Only add ELO features that are actually used by the model
                if 'home_elo' in feature_names:
                    features['home_elo'] = float(elo_features['home_elo'])
                if 'away_elo' in feature_names:
                    features['away_elo'] = float(elo_features['away_elo'])
                if 'elo_diff' in feature_names:
                    features['elo_diff'] = float(elo_features['elo_diff'])
                if 'elo_win_probability' in feature_names:
                    features['elo_win_probability'] = float(elo_features['elo_win_probability'])
                if 'elo_draw_probability' in feature_names:
                    features['elo_draw_probability'] = float(elo_features['elo_draw_probability'])
                if 'elo_loss_probability' in feature_names:
                    features['elo_loss_probability'] = float(elo_features['elo_loss_probability'])
                if 'expected_goal_diff' in feature_names:
                    features['expected_goal_diff'] = float(elo_features.get('elo_expected_goal_diff', 0.0))
            except Exception as e:
                logger.warning(f"Could not add Elo features: {e}")
                # Add default values only for ELO features that are expected by the model
                if 'home_elo' in feature_names:
                    features['home_elo'] = 1500.0
                if 'away_elo' in feature_names:
                    features['away_elo'] = 1500.0
                if 'elo_diff' in feature_names:
                    features['elo_diff'] = 0.0
                if 'elo_win_probability' in feature_names:
                    features['elo_win_probability'] = 0.5
            
            # Return only the features expected by the model, in the correct order
            return {name: features.get(name, 0.0) for name in feature_names if isinstance(name, str)}
        except Exception as e:
            logger.error(f"Error extracting features: {e}")
            # Return a minimal set of features as fallback
            return {
                'home_avg_corners_for': float(home_stats.get('avg_corners_for', 5.0)),
                'home_avg_corners_against': float(home_stats.get('avg_corners_against', 5.0)),
                'away_avg_corners_for': float(away_stats.get('avg_corners_for', 4.5)),
                'away_avg_corners_against': float(away_stats.get('avg_corners_against', 5.5)),
                'home_form_score': float(home_stats.get('form_score', 50)),
                'away_form_score': float(home_stats.get('form_score', 50)),
                'home_elo': 1500.0,
                'away_elo': 1500.0,
                'elo_diff': 0.0,
                'elo_win_probability': 0.5
            }
    
    def _predict_with_rf(self, features: Dict[str, float]) -> Tuple[float, float, float]:
        """Make predictions using Random Forest model"""
        try:
            # Check if model is available before calling predict
            if self.rf_model is None:
                raise ValueError("Random Forest model is not loaded")
            
            # Get feature names from model if possible
            if hasattr(self.rf_model, 'feature_names_in_'):
                feature_names_in_model = self.rf_model.feature_names_in_
                # Create X with features in the same order as they were used during training
                if isinstance(feature_names_in_model[0], str):
                    ordered_features = [features.get(name, 0.0) for name in feature_names_in_model]
                    X = pd.DataFrame([ordered_features], columns=feature_names_in_model)
                else:
                    # Fallback if feature names are not strings
                    X = pd.DataFrame([list(features.values())], columns=list(features.keys()))
            else:
                # If no feature_names_in_ attribute, use the dictionary as is
                X = pd.DataFrame([list(features.values())], columns=list(features.keys()))
                
            # Predict total corners
            total = float(self.rf_model.predict(X)[0])
            
            # Use percentages based on historical home/away distribution
            home_ratio = 0.54 + np.random.normal(0, 0.02)  # Home teams get ~54% of corners on average
            
            # Calculate home and away corners
            home = total * home_ratio
            away = total * (1 - home_ratio)
            
            return total, home, away
        except Exception as e:
            logger.error(f"Error in RF prediction: {e}")
            raise
    
    def _predict_with_xgb(self, features: Dict[str, float]) -> Tuple[float, float, float]:
        """Make predictions using XGBoost model"""
        try:
            # Check if model is available before calling predict
            if self.xgb_model is None:
                raise ValueError("XGBoost model is not loaded")
            
            # Get feature names from model if possible
            if hasattr(self.xgb_model, 'feature_names_in_'):
                feature_names_in_model = self.xgb_model.feature_names_in_
                # Create X with features in the same order as they were used during training
                if isinstance(feature_names_in_model[0], str):
                    ordered_features = [features.get(name, 0.0) for name in feature_names_in_model]
                    X = pd.DataFrame([ordered_features], columns=feature_names_in_model)
                else:
                    # Fallback if feature names are not strings
                    X = pd.DataFrame([list(features.values())], columns=list(features.keys()))
            else:
                # If no feature_names_in_ attribute, use the dictionary as is
                X = pd.DataFrame([list(features.values())], columns=list(features.keys()))
                
            # Predict total corners
            total = float(self.xgb_model.predict(X)[0])
            
            # Use percentages based on historical home/away distribution
            # Slight variation from RF for ensemble diversity
            home_ratio = 0.55 + np.random.normal(0, 0.02)
            
            # Calculate home and away corners
            home = total * home_ratio
            away = total * (1 - home_ratio)
            
            return total, home, away
        except Exception as e:
            logger.error(f"Error in XGBoost prediction: {e}")
            raise
    
    def _statistical_corners_estimate(
        self,
        home_team_id: int,
        away_team_id: int,
        home_stats: Dict[str, Any],
        away_stats: Dict[str, Any],
        league_id: int,
        context_factors: Optional[Dict[str, Any]] = None
    ) -> Tuple[float, float, float]:
        """
        Fallback statistical approach for estimating corners when models are unavailable
        """
        # Base values - offensive and defensive corner stats
        home_team_offensive = home_stats.get('avg_corners_for', 5.0)
        home_team_defensive = 1/max(0.2, home_stats.get('avg_corners_against', 5.0))
        away_team_offensive = away_stats.get('avg_corners_for', 4.5)
        away_team_defensive = 1/max(0.2, away_stats.get('avg_corners_against', 5.5))
        
        # Home advantage coefficient (research shows 20-25% advantage)
        home_advantage = 1.22
        
        # Attacking style indicators
        home_style_factor = min(1.5, max(0.7, home_stats.get('avg_shots', 12.0) / 12.0))
        away_style_factor = min(1.5, max(0.7, away_stats.get('avg_shots', 10.0) / 12.0))
        
        # League adjustment
        league_factor = self.league_factors.get(league_id, 1.0)
        
        # Calculate expected corners
        expected_home_corners = (home_team_offensive * (1/away_team_defensive) * 
                              home_advantage * home_style_factor)
        
        expected_away_corners = (away_team_offensive * (1/home_team_defensive) * 
                              away_style_factor)
        
        # Apply global factors
        expected_home_corners *= league_factor
        expected_away_corners *= league_factor
        
        # Context adjustments
        if context_factors:
            weather_factor = 1.0
            if context_factors.get('is_windy', False):
                weather_factor *= 1.08
            elif context_factors.get('is_rainy', False):
                weather_factor *= 1.05
                
            expected_home_corners *= weather_factor
            expected_away_corners *= weather_factor
        
        total_corners = expected_home_corners + expected_away_corners
        
        # Ensure reasonable ranges
        expected_home_corners = min(12.0, max(2.0, expected_home_corners))
        expected_away_corners = min(10.0, max(1.5, expected_away_corners))
        total_corners = min(20.0, max(5.0, total_corners))
        
        return total_corners, expected_home_corners, expected_away_corners
    
    def _calculate_over_probabilities(
        self, 
        total_corners: float, 
        home_corners: float,
        away_corners: float
    ) -> Dict[str, float]:
        """
        Calculate over/under probabilities using negative binomial distribution,
        which academic research has shown is more appropriate than Poisson for corners.
        """
        try:
            # Parameters for negative binomial based on academic research
            dispersion_param = 8.5
            p = dispersion_param / (dispersion_param + total_corners)
            
            # Thresholds to calculate
            thresholds = [7.5, 8.5, 9.5, 10.5, 11.5, 12.5]
            results = {}
            
            for threshold in thresholds:
                # Calculate probability of threshold or fewer corners
                prob_under = nbinom.cdf(int(threshold), dispersion_param, p)
                # Over probability is complement
                results[f"over_{threshold}"] = 1 - prob_under
            
            return results
        except Exception as e:
            logger.error(f"Error calculating corner probabilities: {e}")
            # Simple fallback
            return {
                "over_7.5": 0.75,
                "over_8.5": 0.65,
                "over_9.5": 0.52,
                "over_10.5": 0.38,
                "over_11.5": 0.26,
                "over_12.5": 0.18
            }
    
    def _calculate_corner_brackets(self, total_corners: float) -> Dict[str, float]:
        """
        Calculate probabilities for corner brackets which are common in betting markets
        """
        # Dispersion parameter for total corners
        dispersion = 8.5
        p = dispersion / (dispersion + total_corners)
        
        # Define corner brackets
        brackets = {
            "0-6": (0, 6),
            "7-9": (7, 9),
            "10-12": (10, 12),
            "13+": (13, float('inf'))
        }
        
        results = {}
        
        for name, (lower, upper) in brackets.items():
            if upper == float('inf'):
                # Probability above lower bound
                prob = 1 - nbinom.cdf(lower-1, dispersion, p)
            else:
                # Probability between bounds
                prob = nbinom.cdf(upper, dispersion, p) - nbinom.cdf(lower-1, dispersion, p)
            
            results[name] = round(float(prob), 3)
        
        return results
    
    def _get_referee_factor(self, referee_id: int) -> float:
        """Get corner adjustment factor for a specific referee"""
        # Example referee factors (would be populated from database)
        referee_factors = {
            1: 1.08,  # Referee who allows more corners
            2: 0.95,  # Referee who calls more fouls, reducing corners
            # More would be added in production
        }
        return referee_factors.get(referee_id, 1.0)
    
    def _calculate_prediction_confidence(
        self,
        total_corners: float,
        home_corners: float,
        away_corners: float,
        home_stats: Dict[str, Any],
        away_stats: Dict[str, Any],
        league_id: int
    ) -> float:
        """Calculate confidence level for the prediction"""
        # Base confidence
        if self.rf_model is not None and self.xgb_model is not None:
            # Higher confidence with ensemble models
            base_confidence = 0.75
        else:
            # Lower confidence with statistical approach
            base_confidence = 0.60
        
        # Data quality factors
        data_quality = 0.0
        if 'avg_corners_for' in home_stats and 'avg_corners_against' in home_stats:
            data_quality += 0.1
        if 'avg_corners_for' in away_stats and 'avg_corners_against' in away_stats:
            data_quality += 0.1
            
        # League factor
        major_leagues = [39, 78, 140, 135, 61]  # Top 5 European leagues
        league_factor = 0.1 if league_id in major_leagues else 0.0
        
        # Combine factors
        confidence = base_confidence + data_quality + league_factor
        
        # Cap at reasonable bounds
        return min(0.95, max(0.5, confidence))
    
    def _get_fallback_prediction(self) -> Dict[str, Any]:
        """Get fallback prediction when the model or calculation fails"""
        total = self.base_corners + np.random.normal(0, 0.7)
        home_ratio = 0.54 + np.random.normal(0, 0.05)
        home = total * home_ratio
        away = total * (1 - home_ratio)
        
        return {
            'total': round(total, 1),
            'home': round(home, 1),
            'away': round(away, 1),
            'over_8.5': round(0.65, 3),
            'over_9.5': round(0.52, 3),
            'over_10.5': round(0.38, 3),
            'corner_brackets': {
                "0-6": round(0.10, 3),
                "7-9": round(0.25, 3),
                "10-12": round(0.40, 3),
                "13+": round(0.25, 3)
            },
            'is_fallback': True,
            'model': 'fallback',
            'confidence': 0.45,
            'fallback_message': "ATENCIÃN: PredicciÃ³n de corners cayÃ³ en fallback"
        }
    
    def predict(self, match_data: Dict[str, Any]) -> Dict[str, float]:
        """
        Realiza predicciÃ³n de cÃ³rners usando el ensemble.
        
        Args:
            match_data: Datos del partido con features necesarias
            
        Returns:
            Dict con predicciones y confianza
        """
        try:
            if not self.is_fitted:
                raise ModelError("El modelo no estÃ¡ entrenado")
                
            # Check if models are available
            if self.rf_model is None or self.xgb_model is None:
                raise ModelError("Los modelos no estÃ¡n disponibles")
                
            # Preparar features
            X = self._prepare_features(match_data)
            
            # Predicciones individuales
            rf_pred = self.rf_model.predict(X)
            xgb_pred = self.xgb_model.predict(X)
            
            # Promediar predicciones con pesos
            weights = [0.5, 0.5]  # Igual peso a ambos modelos
            weighted_home = (
                rf_pred[0] * weights[0] +
                xgb_pred[0] * weights[1]
            )
            weighted_away = (
                rf_pred[1] * weights[0] +
                xgb_pred[1] * weights[1]
            )
            
            # Calcular confianza basada en la varianza de predicciones
            variance = np.var([rf_pred, xgb_pred], axis=0)
            confidence = 1 / (1 + np.mean(variance))
            
            return {
                'home_corners': float(weighted_home),
                'away_corners': float(weighted_away),
                'total_corners': float(weighted_home + weighted_away),
                'model_confidence': float(confidence)
            }
            
        except Exception as e:
            logger.error(f"Error en predicciÃ³n del modelo: {str(e)}")
            raise
    
    def _prepare_features(self, match_data: Dict[str, Any]) -> np.ndarray:
        """
        Prepara features para el modelo desde datos del partido.
        """
        if not self.feature_names:
            raise ModelError("No se han definido las features del modelo")
            
        features = []
        for feature in self.feature_names:
            value = match_data.get(feature)
            if value is None:
                raise ValueError(f"Feature faltante: {feature}")
            features.append(value)
            
        return np.array(features).reshape(1, -1)
    
def predict_corners_with_voting_ensemble(
    home_team_id: int,
    away_team_id: int,
    home_stats: Dict[str, Any],
    away_stats: Dict[str, Any],
    league_id: int,
    context_factors: Optional[Dict[str, Any]] = None,
    referee_id: Optional[int] = None
) -> Dict[str, Any]:
    """
    Get corner predictions using voting ensemble model (RF + XGBoost)
    based on academic research showing this combination achieves highest accuracy.
    
    Args:
        home_team_id: ID of home team
        away_team_id: ID of away team
        home_stats: Stats for home team
        away_stats: Stats for away team
        league_id: League ID
        context_factors: Additional context factors like weather, match importance
        referee_id: Optional referee ID
        
    Returns:
        Dictionary with corner predictions
    """
    model = VotingEnsembleCornersModel()
    return model.predict_corners(
        home_team_id,
        away_team_id,
        home_stats,
        away_stats,
        league_id,
        context_factors,
        referee_id
    )
